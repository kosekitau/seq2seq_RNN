{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_GRUwithAttention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSLcMNQ4189Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7f1b59bb-d703-43d4-a6fa-b56fffe8fc65"
      },
      "source": [
        "!apt install aptitude swig"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "aptitude is already the newest version (0.8.10-6ubuntu1).\n",
            "swig is already the newest version (3.0.12-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNTv69nN5Gxa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "4f638d4b-f430-405e-8395-28a68ca7e9c8"
      },
      "source": [
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.7)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.8)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.4)\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.7)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.8)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.4)\n",
            "No packages will be installed, upgraded, or removed.\n",
            "0 packages upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 0 B of archives. After unpacking 0 B will be used.\n",
            "                            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7bTd26n5JLG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e8a7622-142f-45a0-9a8f-190dc0f6ae0e"
      },
      "source": [
        "!pip install mecab-python3"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.6/dist-packages (0.996.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTbqJmlT5cUz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6772bcc8-2ef5-442b-b8f3-a53a109e4c00"
      },
      "source": [
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'mecab-ipadic-neologd' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg4F0IZR5eoV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f531633-9213-418c-d581-44e4f5e7b841"
      },
      "source": [
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n -a"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[install-mecab-ipadic-NEologd] : Start..\n",
            "[install-mecab-ipadic-NEologd] : Check the existance of libraries\n",
            "[install-mecab-ipadic-NEologd] :     find => ok\n",
            "[install-mecab-ipadic-NEologd] :     sort => ok\n",
            "[install-mecab-ipadic-NEologd] :     head => ok\n",
            "[install-mecab-ipadic-NEologd] :     cut => ok\n",
            "[install-mecab-ipadic-NEologd] :     egrep => ok\n",
            "[install-mecab-ipadic-NEologd] :     mecab => ok\n",
            "[install-mecab-ipadic-NEologd] :     mecab-config => ok\n",
            "[install-mecab-ipadic-NEologd] :     make => ok\n",
            "[install-mecab-ipadic-NEologd] :     curl => ok\n",
            "[install-mecab-ipadic-NEologd] :     sed => ok\n",
            "[install-mecab-ipadic-NEologd] :     cat => ok\n",
            "[install-mecab-ipadic-NEologd] :     diff => ok\n",
            "[install-mecab-ipadic-NEologd] :     tar => ok\n",
            "[install-mecab-ipadic-NEologd] :     unxz => ok\n",
            "[install-mecab-ipadic-NEologd] :     xargs => ok\n",
            "[install-mecab-ipadic-NEologd] :     grep => ok\n",
            "[install-mecab-ipadic-NEologd] :     iconv => ok\n",
            "[install-mecab-ipadic-NEologd] :     patch => ok\n",
            "[install-mecab-ipadic-NEologd] :     which => ok\n",
            "[install-mecab-ipadic-NEologd] :     file => ok\n",
            "[install-mecab-ipadic-NEologd] :     openssl => ok\n",
            "[install-mecab-ipadic-NEologd] :     awk => ok\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : mecab-ipadic-NEologd is already up-to-date\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : mecab-ipadic-NEologd will be install to /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Make mecab-ipadic-NEologd\n",
            "[make-mecab-ipadic-NEologd] : Start..\n",
            "[make-mecab-ipadic-NEologd] : Check local seed directory\n",
            "[make-mecab-ipadic-NEologd] : Check local seed file\n",
            "[make-mecab-ipadic-NEologd] : Check local build directory\n",
            "[make-mecab-ipadic-NEologd] : Download original mecab-ipadic file\n",
            "[make-mecab-ipadic-NEologd] : Original mecab-ipadic file is already there.\n",
            "[make-mecab-ipadic-NEologd] : Decompress original mecab-ipadic file\n",
            "[make-mecab-ipadic-NEologd] : Delete old mecab-ipadic-2.7.0-20070801-neologd-20200430 directory\n",
            "mecab-ipadic-2.7.0-20070801/\n",
            "mecab-ipadic-2.7.0-20070801/README\n",
            "mecab-ipadic-2.7.0-20070801/AUTHORS\n",
            "mecab-ipadic-2.7.0-20070801/COPYING\n",
            "mecab-ipadic-2.7.0-20070801/ChangeLog\n",
            "mecab-ipadic-2.7.0-20070801/INSTALL\n",
            "mecab-ipadic-2.7.0-20070801/Makefile.am\n",
            "mecab-ipadic-2.7.0-20070801/Makefile.in\n",
            "mecab-ipadic-2.7.0-20070801/NEWS\n",
            "mecab-ipadic-2.7.0-20070801/aclocal.m4\n",
            "mecab-ipadic-2.7.0-20070801/config.guess\n",
            "mecab-ipadic-2.7.0-20070801/config.sub\n",
            "mecab-ipadic-2.7.0-20070801/configure\n",
            "mecab-ipadic-2.7.0-20070801/configure.in\n",
            "mecab-ipadic-2.7.0-20070801/install-sh\n",
            "mecab-ipadic-2.7.0-20070801/missing\n",
            "mecab-ipadic-2.7.0-20070801/mkinstalldirs\n",
            "mecab-ipadic-2.7.0-20070801/Adj.csv\n",
            "mecab-ipadic-2.7.0-20070801/Adnominal.csv\n",
            "mecab-ipadic-2.7.0-20070801/Adverb.csv\n",
            "mecab-ipadic-2.7.0-20070801/Auxil.csv\n",
            "mecab-ipadic-2.7.0-20070801/Conjunction.csv\n",
            "mecab-ipadic-2.7.0-20070801/Filler.csv\n",
            "mecab-ipadic-2.7.0-20070801/Interjection.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.adjv.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.adverbal.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.demonst.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.nai.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.name.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.number.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.org.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.others.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.place.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.proper.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.verbal.csv\n",
            "mecab-ipadic-2.7.0-20070801/Others.csv\n",
            "mecab-ipadic-2.7.0-20070801/Postp-col.csv\n",
            "mecab-ipadic-2.7.0-20070801/Postp.csv\n",
            "mecab-ipadic-2.7.0-20070801/Prefix.csv\n",
            "mecab-ipadic-2.7.0-20070801/Suffix.csv\n",
            "mecab-ipadic-2.7.0-20070801/Symbol.csv\n",
            "mecab-ipadic-2.7.0-20070801/Verb.csv\n",
            "mecab-ipadic-2.7.0-20070801/char.def\n",
            "mecab-ipadic-2.7.0-20070801/feature.def\n",
            "mecab-ipadic-2.7.0-20070801/left-id.def\n",
            "mecab-ipadic-2.7.0-20070801/matrix.def\n",
            "mecab-ipadic-2.7.0-20070801/pos-id.def\n",
            "mecab-ipadic-2.7.0-20070801/rewrite.def\n",
            "mecab-ipadic-2.7.0-20070801/right-id.def\n",
            "mecab-ipadic-2.7.0-20070801/unk.def\n",
            "mecab-ipadic-2.7.0-20070801/dicrc\n",
            "mecab-ipadic-2.7.0-20070801/RESULT\n",
            "[make-mecab-ipadic-NEologd] : Configure custom system dictionary on /content/mecab-ipadic-neologd/libexec/../build/mecab-ipadic-2.7.0-20070801-neologd-20200430\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for working aclocal-1.4... missing\n",
            "checking for working autoconf... missing\n",
            "checking for working automake-1.4... missing\n",
            "checking for working autoheader... missing\n",
            "checking for working makeinfo... missing\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking for mecab-config... /usr/bin/mecab-config\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "[make-mecab-ipadic-NEologd] : Encode the character encoding of system dictionary resources from EUC_JP to UTF-8\n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Auxil.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adnominal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adj.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Interjection.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Others.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.nai.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Postp.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Postp-col.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.others.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adverb.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.adjv.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Verb.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.verbal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.place.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Suffix.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Conjunction.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.demonst.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Symbol.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.org.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Prefix.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.number.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.adverbal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.proper.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.name.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Filler.csv \n",
            "rm ./Auxil.csv \n",
            "rm ./Adnominal.csv \n",
            "rm ./Adj.csv \n",
            "rm ./Interjection.csv \n",
            "rm ./Others.csv \n",
            "rm ./Noun.nai.csv \n",
            "rm ./Postp.csv \n",
            "rm ./Postp-col.csv \n",
            "rm ./Noun.others.csv \n",
            "rm ./Adverb.csv \n",
            "rm ./Noun.adjv.csv \n",
            "rm ./Verb.csv \n",
            "rm ./Noun.verbal.csv \n",
            "rm ./Noun.csv \n",
            "rm ./Noun.place.csv \n",
            "rm ./Suffix.csv \n",
            "rm ./Conjunction.csv \n",
            "rm ./Noun.demonst.csv \n",
            "rm ./Symbol.csv \n",
            "rm ./Noun.org.csv \n",
            "rm ./Prefix.csv \n",
            "rm ./Noun.number.csv \n",
            "rm ./Noun.adverbal.csv \n",
            "rm ./Noun.proper.csv \n",
            "rm ./Noun.name.csv \n",
            "rm ./Filler.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./unk.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./pos-id.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./matrix.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./right-id.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./char.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./feature.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./left-id.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./rewrite.def \n",
            "rm ./unk.def \n",
            "rm ./pos-id.def \n",
            "rm ./matrix.def \n",
            "rm ./right-id.def \n",
            "rm ./char.def \n",
            "rm ./feature.def \n",
            "rm ./left-id.def \n",
            "rm ./rewrite.def \n",
            "mv ./rewrite.def.utf8 ./rewrite.def \n",
            "mv ./char.def.utf8 ./char.def \n",
            "mv ./Noun.number.csv.utf8 ./Noun.number.csv \n",
            "mv ./matrix.def.utf8 ./matrix.def \n",
            "mv ./Noun.others.csv.utf8 ./Noun.others.csv \n",
            "mv ./unk.def.utf8 ./unk.def \n",
            "mv ./pos-id.def.utf8 ./pos-id.def \n",
            "mv ./Adnominal.csv.utf8 ./Adnominal.csv \n",
            "mv ./Postp-col.csv.utf8 ./Postp-col.csv \n",
            "mv ./Noun.demonst.csv.utf8 ./Noun.demonst.csv \n",
            "mv ./Adj.csv.utf8 ./Adj.csv \n",
            "mv ./Noun.org.csv.utf8 ./Noun.org.csv \n",
            "mv ./Noun.nai.csv.utf8 ./Noun.nai.csv \n",
            "mv ./Noun.place.csv.utf8 ./Noun.place.csv \n",
            "mv ./right-id.def.utf8 ./right-id.def \n",
            "mv ./Conjunction.csv.utf8 ./Conjunction.csv \n",
            "mv ./feature.def.utf8 ./feature.def \n",
            "mv ./Others.csv.utf8 ./Others.csv \n",
            "mv ./Noun.name.csv.utf8 ./Noun.name.csv \n",
            "mv ./Interjection.csv.utf8 ./Interjection.csv \n",
            "mv ./Noun.csv.utf8 ./Noun.csv \n",
            "mv ./Noun.proper.csv.utf8 ./Noun.proper.csv \n",
            "mv ./Noun.adjv.csv.utf8 ./Noun.adjv.csv \n",
            "mv ./left-id.def.utf8 ./left-id.def \n",
            "mv ./Noun.verbal.csv.utf8 ./Noun.verbal.csv \n",
            "mv ./Noun.adverbal.csv.utf8 ./Noun.adverbal.csv \n",
            "mv ./Filler.csv.utf8 ./Filler.csv \n",
            "mv ./Auxil.csv.utf8 ./Auxil.csv \n",
            "mv ./Prefix.csv.utf8 ./Prefix.csv \n",
            "mv ./Postp.csv.utf8 ./Postp.csv \n",
            "mv ./Symbol.csv.utf8 ./Symbol.csv \n",
            "mv ./Verb.csv.utf8 ./Verb.csv \n",
            "mv ./Suffix.csv.utf8 ./Suffix.csv \n",
            "mv ./Adverb.csv.utf8 ./Adverb.csv \n",
            "[make-mecab-ipadic-NEologd] : Fix yomigana field of IPA dictionary\n",
            "patching file Noun.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Verb.csv\n",
            "patching file Noun.verbal.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.adverbal.csv\n",
            "patching file Noun.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.org.csv\n",
            "patching file Noun.others.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Noun.verbal.csv\n",
            "patching file Prefix.csv\n",
            "patching file Suffix.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Noun.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.org.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Noun.verbal.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.org.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Suffix.csv\n",
            "patching file Noun.demonst.csv\n",
            "patching file Noun.csv\n",
            "patching file Noun.name.csv\n",
            "[make-mecab-ipadic-NEologd] : Copy user dictionary resource\n",
            "[make-mecab-ipadic-NEologd] : Install adverb entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adverb-dict-seed.20150623.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install interjection entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-interjection-dict-seed.20170216.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install noun orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-common-noun-ortho-variant-dict-seed.20170228.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install noun orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-proper-noun-ortho-variant-dict-seed.20161110.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install entries of orthographic variant of a noun used as verb form using /content/mecab-ipadic-neologd/libexec/../seed/neologd-noun-sahen-conn-ortho-variant-dict-seed.20160323.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install frequent adjective orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-std-dict-seed.20151126.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install infrequent adjective orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-exp-dict-seed.20151126.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install adjective verb orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-verb-dict-seed.20160324.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install infrequent datetime representation entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-date-time-infreq-dict-seed.20190415.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install infrequent quantity representation entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-quantity-infreq-dict-seed.20190415.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install entries of ill formed words using /content/mecab-ipadic-neologd/libexec/../seed/neologd-ill-formed-words-dict-seed.20170127.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Re-Index system dictionary\n",
            "reading ./unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "reading ./Auxil.csv ... 199\n",
            "reading ./Adnominal.csv ... 135\n",
            "reading ./neologd-interjection-dict-seed.20170216.csv ... 4701\n",
            "reading ./Adj.csv ... 27210\n",
            "reading ./Interjection.csv ... 252\n",
            "reading ./neologd-adjective-exp-dict-seed.20151126.csv ... 1051146\n",
            "reading ./neologd-date-time-infreq-dict-seed.20190415.csv ... 16866\n",
            "reading ./Others.csv ... 2\n",
            "reading ./Noun.nai.csv ... 42\n",
            "reading ./Postp.csv ... 146\n",
            "reading ./Postp-col.csv ... 91\n",
            "reading ./neologd-quantity-infreq-dict-seed.20190415.csv ... 229216\n",
            "reading ./Noun.others.csv ... 153\n",
            "reading ./Adverb.csv ... 3032\n",
            "reading ./neologd-common-noun-ortho-variant-dict-seed.20170228.csv ... 152869\n",
            "reading ./Noun.adjv.csv ... 3328\n",
            "reading ./Verb.csv ... 130750\n",
            "reading ./Noun.verbal.csv ... 12150\n",
            "reading ./neologd-ill-formed-words-dict-seed.20170127.csv ... 60616\n",
            "reading ./Noun.csv ... 60734\n",
            "reading ./neologd-adjective-verb-dict-seed.20160324.csv ... 20268\n",
            "reading ./neologd-adverb-dict-seed.20150623.csv ... 139792\n",
            "reading ./neologd-proper-noun-ortho-variant-dict-seed.20161110.csv ... 138379\n",
            "reading ./neologd-noun-sahen-conn-ortho-variant-dict-seed.20160323.csv ... 26058\n",
            "reading ./Noun.place.csv ... 73194\n",
            "tcmalloc: large alloc 1157636096 bytes == 0x557d4a900000 @  0x7f6bfcaf9887 0x7f6bfbc68b8b 0x7f6bfbc6a133 0x7f6bfc76ea66 0x7f6bfc742e53 0x7f6bfc328b97 0x557cfcd4d67a\n",
            "reading ./mecab-user-dict-seed.20200430.csv ... 3190186\n",
            "reading ./neologd-adjective-std-dict-seed.20151126.csv ... 507812\n",
            "reading ./Suffix.csv ... 1448\n",
            "reading ./Conjunction.csv ... 171\n",
            "reading ./Noun.demonst.csv ... 120\n",
            "reading ./Symbol.csv ... 208\n",
            "reading ./Noun.org.csv ... 17149\n",
            "reading ./Prefix.csv ... 224\n",
            "reading ./Noun.number.csv ... 42\n",
            "reading ./Noun.adverbal.csv ... 808\n",
            "reading ./Noun.proper.csv ... 27493\n",
            "reading ./Noun.name.csv ... 34215\n",
            "reading ./Filler.csv ... 19\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "[make-mecab-ipadic-NEologd] : Make custom system dictionary on /content/mecab-ipadic-neologd/libexec/../build/mecab-ipadic-2.7.0-20070801-neologd-20200430\n",
            "make: Nothing to be done for 'all'.\n",
            "[make-mecab-ipadic-NEologd] : Finish..\n",
            "[install-mecab-ipadic-NEologd] : Get results of tokenize test\n",
            "[test-mecab-ipadic-NEologd] : Start..\n",
            "[test-mecab-ipadic-NEologd] : Replace timestamp from 'git clone' date to 'git commit' date\n",
            "[test-mecab-ipadic-NEologd] : Get buzz phrases\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1493  100  1493    0     0   1568      0 --:--:-- --:--:-- --:--:--  1566\n",
            "[test-mecab-ipadic-NEologd] : Get difference between default system dictionary and mecab-ipadic-NEologd\n",
            "[test-mecab-ipadic-NEologd] : Tokenize phrase using default system dictionary\n",
            "[test-mecab-ipadic-NEologd] : Tokenize phrase using mecab-ipadic-NEologd\n",
            "[test-mecab-ipadic-NEologd] : Get result of diff\n",
            "[test-mecab-ipadic-NEologd] : Please check difference between default system dictionary and mecab-ipadic-NEologd\n",
            "\n",
            "default system dictionary\t  |\tmecab-ipadic-NEologd\n",
            "アド 街 \t\t\t  |\tアド街 \n",
            "報道 特集 \t\t\t  |\t報道特集 \n",
            "福 薗 好 政 \t\t\t  |\t福薗 好 政 \n",
            "電波 少年 \t\t\t  |\t電波少年 \n",
            "ブラ タモリ \t\t\t  |\tブラタモリ \n",
            "風 磨 \t\t\t\t  |\t風磨 \n",
            "4 次 感染 \t\t\t  |\t4次 感染 \n",
            "\n",
            "[test-mecab-ipadic-NEologd] : Finish..\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Please check the list of differences in the upper part.\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Do you want to install mecab-ipadic-NEologd? Type yes or no.\n",
            "[install-mecab-ipadic-NEologd] : OK. Let's install mecab-ipadic-NEologd.\n",
            "[install-mecab-ipadic-NEologd] : Start..\n",
            "[install-mecab-ipadic-NEologd] : /usr/lib/x86_64-linux-gnu/mecab/dic is current user's directory\n",
            "[install-mecab-ipadic-NEologd] : Make install to /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            "make[1]: Entering directory '/content/mecab-ipadic-neologd/build/mecab-ipadic-2.7.0-20070801-neologd-20200430'\n",
            "make[1]: Nothing to be done for 'install-exec-am'.\n",
            "/bin/bash ./mkinstalldirs /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            " /usr/bin/install -c -m 644 ./matrix.bin /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/matrix.bin\n",
            " /usr/bin/install -c -m 644 ./char.bin /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/char.bin\n",
            " /usr/bin/install -c -m 644 ./sys.dic /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/sys.dic\n",
            " /usr/bin/install -c -m 644 ./unk.dic /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/unk.dic\n",
            " /usr/bin/install -c -m 644 ./left-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/left-id.def\n",
            " /usr/bin/install -c -m 644 ./right-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/right-id.def\n",
            " /usr/bin/install -c -m 644 ./rewrite.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/rewrite.def\n",
            " /usr/bin/install -c -m 644 ./pos-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/pos-id.def\n",
            " /usr/bin/install -c -m 644 ./dicrc /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/dicrc\n",
            "make[1]: Leaving directory '/content/mecab-ipadic-neologd/build/mecab-ipadic-2.7.0-20070801-neologd-20200430'\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Install completed.\n",
            "[install-mecab-ipadic-NEologd] : When you use MeCab, you can set '/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd' as a value of '-d' option of MeCab.\n",
            "[install-mecab-ipadic-NEologd] : Usage of mecab-ipadic-NEologd is here.\n",
            "Usage:\n",
            "    $ mecab -d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd ...\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Finish..\n",
            "[install-mecab-ipadic-NEologd] : Finish..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGgjDAsJ5o9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import MeCab\n",
        "import subprocess\n",
        "\n",
        "cmd='echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
        "path = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
        "                           shell=True).communicate()[0]).decode('utf-8')\n",
        "mecab = MeCab.Tagger(\"-d {0} -Owakati\".format(path))\n",
        "#mecab = MeCab.Tagger(\"-Owakati\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOlyG1zf5thB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "22d378dd-0e75-410a-b08d-87fbeede82f7"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        " \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        " \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import gensim\n",
        "\n",
        "hidden_size = 256\n",
        "model_dir = 'drive/My Drive/embedding/japanese_wiki/entity_vector.model.bin'\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(model_dir, binary=True)\n",
        "embedding_vector = torch.from_numpy(model.vectors)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvR7kbDs6U-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0 #start of string\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 30 \n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {} #単語の頻度\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # 辞書に登録してある単語の種類\n",
        " \n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        " \n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McSv1upn6jDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalizeString(s):\n",
        "    s = re.sub('\\r', '', s)\n",
        "    s = re.sub('\\n', '', s)\n",
        "    s = re.sub(' ', ' ', s)\n",
        "    s = mecab.parse(s)[:-2] #分かち書き\n",
        "    return s #sentence\n",
        "\n",
        "#pairsの作成と、inputLang、outputLangの初期化\n",
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        " \n",
        "    # lang1, lang2は言語の洗濯(lang1が英語、lang2がフランス)\n",
        "    lines = open('drive/My Drive/dataset/taiwahatan/0516_30token.txt', encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        " \n",
        "    # l = 'eng ¥t french'\n",
        "    # lに対してユニコードや正規化の処理\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    \n",
        "    # 言語の翻訳の順番を変えるだけ\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        #初期化\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        " \n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXOIW1tb8yje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "f0a7fb98-cc02-40f2-889f-bad047ed46df"
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    #テキストファイルを読んで行に分割し、行をペアに分割する\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse) \n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    #単語の辞書を作る\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0]) #入力の1文\n",
        "        output_lang.addSentence(pair[1]) #出力の一文\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        " \n",
        " \n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(len(pairs)) #shape->[10599, 2]\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 18121 sentence pairs\n",
            "Trimmed to 18121 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 6095\n",
            "eng 5960\n",
            "18121\n",
            "['退屈 が 忌々しい です', 'ありさ ん です か ？']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjAGFY9q9ENT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#入力文を反転させる\n",
        "for i in range(len(pairs)):\n",
        "  pairs[i][0] = ' '.join(pairs[i][0].split(' ')[::-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE1bAsS09gYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, text_embedding_vectors, dropout_p):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        # input_size：辞書の単語種類数、 hidden_size：分散表現の次元数\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "        embeddings=text_embedding_vectors, freeze=True) # [*, 200]\n",
        "        #self.lstm = nn.GRU(text_embedding_vectors.shape[1], hidden_size) #[200, 256]\n",
        "        self.lstm = nn.LSTM(text_embedding_vectors.shape[1], hidden_size, dropout=dropout_p) #[200, 256]\n",
        " \n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1) #[1, 1, 256]\n",
        "        output = embedded\n",
        "        output, hidden = self.lstm(output, hidden) #[1, 1, 256], [1, 1, 256]\n",
        "        #出力と隠れ状態\n",
        "        #隠れ状態を出力する\n",
        "        return output, hidden\n",
        "         \n",
        "    #隠れ状態0の初期化\n",
        "    def initHidden(self):\n",
        "        return (torch.zeros(1, 1, self.hidden_size, device=device),\n",
        "                torch.zeros(1, 1, self.hidden_size, device=device))\n",
        "        #return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_o21hp-9hqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        #self.lstm = nn.GRU(hidden_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        " \n",
        "    #hidedenはencoderの隠れ状態\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.lstm(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        " \n",
        "    def initHidden(self):\n",
        "        #return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        return (torch.zeros(1, 1, self.hidden_size, device=device),\n",
        "                torch.zeros(1, 1, self.hidden_size, device=device))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIf7Lh5-ApLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, text_embedding_vectors, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size #RNNの重みの次元数\n",
        "        self.embedding = nn.Embedding.from_pretrained(embeddings=text_embedding_vectors, freeze=True)\n",
        "        self.output_size = output_size #単語数\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length #最大単語数\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        #self.lstm = nn.GRU(text_embedding_vectors.shape[1], self.hidden_size)\n",
        "        self.lstm = nn.LSTM(text_embedding_vectors.shape[1], self.hidden_size, dropout=dropout_p)\n",
        "        self.out = nn.Linear(self.hidden_size*2, self.output_size)\n",
        " \n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        #input:[1], hidden:[1,1,256], encoder_outputs:[10,256]\n",
        "        embedded = self.embedding(input).view(1, 1, -1) # [1,1,256]\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        query, hidden = self.lstm(embedded, hidden) # [1,1,256], ([1,1,256], [1,1,256])\n",
        "\n",
        "        #内積注意でAttention Weightを求める\n",
        "        attn_weights = torch.matmul(query[0], encoder_outputs.transpose(1, 0)) # [1,30]\n",
        "        attn_weights = F.softmax(attn_weights, -1)\n",
        "\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0)) # [1,1,256]\n",
        "        \n",
        "        output = torch.cat((query[0], attn_applied[0]), 1)\n",
        "        output = F.log_softmax(self.out(output), dim=1)\n",
        "\n",
        "        return output, hidden, attn_weights\n",
        " \n",
        "    def initHidden(self):\n",
        "        #return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        #隠れ状態と記憶セルの初期化\n",
        "        return (torch.zeros(1, 1, self.hidden_size, device=device),\n",
        "                torch.zeros(1, 1, self.hidden_size, device=device))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25BpA2ozEssm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    #各文を単語indexのならびに\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1) #[[2], [25], [9]....]の形に\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    #pairは各文(0が入力)\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyYD7534FWFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "4148de5d-9e61-4803-bee9-71b4830f7d99"
      },
      "source": [
        "training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(2)]\n",
        "training_pairs"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor([[ 21],\n",
              "          [  7],\n",
              "          [341],\n",
              "          [ 10],\n",
              "          [790],\n",
              "          [  1]], device='cuda:0'), tensor([[857],\n",
              "          [ 57],\n",
              "          [ 47],\n",
              "          [  1]], device='cuda:0')), (tensor([[   3],\n",
              "          [ 110],\n",
              "          [1272],\n",
              "          [1709],\n",
              "          [   1]], device='cuda:0'), tensor([[  46],\n",
              "          [  17],\n",
              "          [3891],\n",
              "          [3892],\n",
              "          [  19],\n",
              "          [ 306],\n",
              "          [  92],\n",
              "          [  21],\n",
              "          [   1]], device='cuda:0'))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV0fJAxsFZL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#teaching_forceは学習時のエンコーダーに生成されたtokenではなく、\n",
        "#教師データを入力すること\n",
        "teacher_forcing_ratio = 0.5\n",
        " \n",
        " \n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        " \n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        " \n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        " \n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        " \n",
        "    loss = 0\n",
        "    #input_tensorは[その文の単語数, 1]のテンソル、つまり1文のデータ\n",
        "    for ei in range(input_length):\n",
        "        #1文字のindexと隠れ状態を入れていく\n",
        "        #input_tensor[ei]:[1], encoder_hidden:([1,1,256], [1,1,256])\n",
        "        encoder_output, encoder_hidden, = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        #encoder_output:[1,1,256], encoder_hidden:[1,1,256]\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        " \n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    #エンコーダーの隠れ状態と記憶セル\n",
        "    decoder_hidden = encoder_hidden\n",
        "    \n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            #decoder_input:[1], decoder_hidden:[1,1,256], encoder_outputs:[10,256]\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            #decoder_output:[1,2803], decoder_hidden:[1,1,256], decoder_attention:[1,10]\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        " \n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        " \n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        " \n",
        "    loss.backward()\n",
        " \n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        " \n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyKl_nktFo2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        " \n",
        " \n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        " \n",
        " \n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B22IW8v2Fq-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        " \n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        " \n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        #########\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        " \n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        " \n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        " \n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        " \n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3hzQP3lFsqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        " \n",
        " \n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2cZhDpcFula",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        " \n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        " \n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        " \n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        " \n",
        "        decoder_hidden = encoder_hidden\n",
        "        \n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        " \n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<eos>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        " \n",
        "            decoder_input = topi.squeeze().detach()\n",
        " \n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKBHKtYyFym8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('入力：', pair[0])\n",
        "        print('正解', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('応答：', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91xh9qNMF0r2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5773a27f-0d23-435a-d8a2-6fe83db649b8"
      },
      "source": [
        "output_lang.n_words"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5960"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW_ARHYUF2U0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "2c92c839-bd19-46bd-99b3-a30257dc0fe1"
      },
      "source": [
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size, embedding_vector, dropout_p=0.5).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size,  embedding_vector, output_lang.n_words, dropout_p=0.5).to(device)\n",
        "\n",
        "#trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2m 11s (- 30m 39s) (5000 6%) 4.6444\n",
            "4m 10s (- 27m 7s) (10000 13%) 4.4197\n",
            "6m 11s (- 24m 46s) (15000 20%) 4.5741\n",
            "8m 14s (- 22m 39s) (20000 26%) 4.6243\n",
            "10m 16s (- 20m 32s) (25000 33%) 4.6227\n",
            "12m 20s (- 18m 30s) (30000 40%) 4.6560\n",
            "14m 24s (- 16m 27s) (35000 46%) 4.6693\n",
            "16m 30s (- 14m 27s) (40000 53%) 4.6506\n",
            "18m 34s (- 12m 22s) (45000 60%) 4.5542\n",
            "20m 36s (- 10m 18s) (50000 66%) 4.5539\n",
            "22m 40s (- 8m 14s) (55000 73%) 4.5284\n",
            "24m 45s (- 6m 11s) (60000 80%) 4.5536\n",
            "26m 50s (- 4m 7s) (65000 86%) 4.6297\n",
            "28m 56s (- 2m 4s) (70000 93%) 4.6103\n",
            "31m 1s (- 0m 0s) (75000 100%) 4.5553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6TZXzA4F6Df",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "990539f0-c0a8-49d6-cbaf-07ec77cf816e"
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "入力： 。 ます い て 見 を 映画 で スマホ 時々\n",
            "正解 スマホ で 使え ます\n",
            "応答： じゃあ <eos>\n",
            "\n",
            "入力： ね です 有名 で スイカ\n",
            "正解 スイカ は おいしい です ね\n",
            "応答： スイカ は の です ね <eos>\n",
            "\n",
            "入力： ． よ う ましょ 行き に 一緒 今度 たら よかっ\n",
            "正解 加茂水族館 は クラゲ が 有名 です ね\n",
            "応答： 海 に は 海 海 を は 海 に 行く は 海 は 海 へ は 海 ます ね <eos>\n",
            "\n",
            "入力： ね だ そう 降り 雨\n",
            "正解 おは よー\n",
            "応答： そう <eos>\n",
            "\n",
            "入力： 。 ね です 嫌 と 降る が 雨\n",
            "正解 うん\n",
            "応答： 喧嘩 は ビタミンC が いい です ね <eos>\n",
            "\n",
            "入力： ！ です 大好き フレンチトースト の モーニング\n",
            "正解 サンド が 美味しい です ね\n",
            "応答： こんばんは は の です ね <eos>\n",
            "\n",
            "入力： ね う でしょ\n",
            "正解 なにか 食べ た の ？\n",
            "応答： こんにちは <eos>\n",
            "\n",
            "入力： ね です 薄い が 興味\n",
            "正解 嫌い じゃ ない 程度 だ よ\n",
            "応答： 君 が 好き 聞い です ね <eos>\n",
            "\n",
            "入力： ? か ます きき を 音楽 どんな\n",
            "正解 こんばんは 。 今日 は 割と 涼しい ね\n",
            "応答： こんばんは は <eos>\n",
            "\n",
            "入力： か ます し 利用 よく\n",
            "正解 施設 は 広い らしい です\n",
            "応答： いいえ 行く ちゅ です ね <eos>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0llwy93sO2E0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}